{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a9eb90-335c-4214-8bb6-fd1edbe3ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My OpenAI Key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a712b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "90ba21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using sdsc-data-llama collection from MongoDB to populate LLamaIndex\n",
    "from llama_index.storage.index_store import MongoIndexStore\n",
    "from llama_index import StorageContext, VectorStoreIndex, SimpleMongoReader, load_index_from_storage\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "host = \"localhost\"\n",
    "port = 27017\n",
    "db_name = \"mydatabase\"\n",
    "collection_name = 'sdsc-data-llama'\n",
    "\n",
    "index_store = MongoIndexStore.from_host_and_port(\n",
    "    host = host,\n",
    "    port = port,\n",
    "    db_name = db_name,\n",
    "    namespace = f'{db_name}.{collection_name}'\n",
    ")\n",
    "\n",
    "# create storage context\n",
    "storage_context = StorageContext.from_defaults(index_store=index_store)\n",
    "\n",
    "query_dict = {}\n",
    "field_names = [\"news\", \"title\", \"publishdate\"]\n",
    "reader = SimpleMongoReader(host, port)\n",
    "documents = reader.load_data(db_name, collection_name, field_names, query_dict=query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827f7088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2951\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa32a324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 72038 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 72038 tokens\n",
      "50\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 64188 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 64188 tokens\n",
      "100\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 85787 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 85787 tokens\n",
      "150\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 52674 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 52674 tokens\n",
      "200\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 38263 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 38263 tokens\n",
      "250\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 36414 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 36414 tokens\n",
      "300\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 65940 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 65940 tokens\n",
      "350\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 68572 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 68572 tokens\n",
      "400\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 77947 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 77947 tokens\n",
      "450\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 61670 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 61670 tokens\n",
      "500\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 55369 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 55369 tokens\n",
      "550\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 64915 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 64915 tokens\n",
      "600\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 65607 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 65607 tokens\n",
      "650\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 82356 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 82356 tokens\n",
      "700\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 74614 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 74614 tokens\n",
      "750\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 75007 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 75007 tokens\n",
      "800\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 80836 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 80836 tokens\n",
      "850\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 82068 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 82068 tokens\n",
      "900\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 101669 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 101669 tokens\n",
      "950\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 73582 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 73582 tokens\n",
      "1000\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 66359 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 66359 tokens\n",
      "1050\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 76715 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 76715 tokens\n",
      "1100\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 58066 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 58066 tokens\n",
      "1150\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 52338 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 52338 tokens\n",
      "1200\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 53074 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 53074 tokens\n",
      "1250\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 64100 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 64100 tokens\n",
      "1300\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 54504 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 54504 tokens\n",
      "1350\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 62985 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 62985 tokens\n",
      "1400\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 83849 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 83849 tokens\n",
      "1450\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 55795 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 55795 tokens\n",
      "1500\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 73000 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 73000 tokens\n",
      "1550\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 69959 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 69959 tokens\n",
      "1600\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 83902 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 83902 tokens\n",
      "1650\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 66025 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 66025 tokens\n",
      "1700\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 74539 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 74539 tokens\n",
      "1750\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 62374 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 62374 tokens\n",
      "1800\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 66657 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 66657 tokens\n",
      "1850\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 74852 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 74852 tokens\n",
      "1900\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 89652 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 89652 tokens\n",
      "1950\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 65171 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 65171 tokens\n",
      "2000\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 82231 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 82231 tokens\n",
      "2050\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 77131 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 77131 tokens\n",
      "2100\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 62339 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 62339 tokens\n",
      "2150\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 54931 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 54931 tokens\n",
      "2200\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 58339 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 58339 tokens\n",
      "2250\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 87901 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 87901 tokens\n",
      "2300\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 103852 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 103852 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 83447 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 83447 tokens\n",
      "2400\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 53221 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 53221 tokens\n",
      "2450\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 77240 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 77240 tokens\n",
      "2500\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 74683 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 74683 tokens\n",
      "2550\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 75665 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 75665 tokens\n",
      "2600\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 77099 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 77099 tokens\n",
      "2650\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 80263 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 80263 tokens\n",
      "2700\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 81127 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 81127 tokens\n",
      "2750\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 95560 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 95560 tokens\n",
      "2800\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 55327 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 55327 tokens\n",
      "2850\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 92682 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 92682 tokens\n",
      "2900\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 99447 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 99447 tokens\n",
      "2950\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(documents):\n\u001b[0;32m----> 9\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     index \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mfrom_documents(documents[i:batch \u001b[38;5;241m+\u001b[39m i])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "batch = 50\n",
    "index = VectorStoreIndex.from_documents(documents[:batch])\n",
    "\n",
    "for i in range(batch, len(documents), batch):\n",
    "    print(i)\n",
    "    if batch + i > len(documents):\n",
    "        index = index.from_documents(documents[i:])\n",
    "    else:\n",
    "        index = index.from_documents(documents[i:batch + i])\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "807238b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 72038 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 72038 tokens\n"
     ]
    }
   ],
   "source": [
    "#index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b6fd92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir = './storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "228a520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.set_index_id('model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f128b1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model1'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.index_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "317436a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f7f4a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 37 tokens\n",
      "> [retrieve] Total embedding token usage: 37 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1717 tokens\n",
      "> [get_response] Total LLM token usage: 1717 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The major party nominees in the West Virginia Senate Race in 2018 were Joe Manchin (Democrat) and Patrick Morrisey (Republican).</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    Who are the major party nominess in the West Virginia Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f94333a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 25 tokens\n",
      "> [retrieve] Total embedding token usage: 25 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 858 tokens\n",
      "> [get_response] Total LLM token usage: 858 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The major party nominees in the West Virginia Senate Race in 2018 are Joe Manchin (Democrat) and Patrick Morrisey (Republican).</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Who are the major party nominess in the West Virginia Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "094b1a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 34 tokens\n",
      "> [retrieve] Total embedding token usage: 34 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1690 tokens\n",
      "> [get_response] Total LLM token usage: 1690 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Joe Manchin.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    Who is the winner of the West Virginia Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0bbd5454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 22 tokens\n",
      "> [retrieve] Total embedding token usage: 22 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 857 tokens\n",
      "> [get_response] Total LLM token usage: 857 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The winner of the West Virginia Senate Race in 2018 was Joe Manchin.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Who is the winner of the West Virginia Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3b6883ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 60 tokens\n",
      "> [retrieve] Total embedding token usage: 60 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1767 tokens\n",
      "> [get_response] Total LLM token usage: 1767 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Joe Manchin won his 2018 Senate reelection in West Virginia, while Hillary Clinton lost the state in her 2016 presidential campaign. Manchin won the state by a margin of 3.6%, while Clinton lost by a margin of 42.2%. Manchin was able to win the state by appealing to rural and small-town voters, while Clinton struggled with the same demographic. Manchin defended the coal industry, while Clinton's policies ran afoul of rural and small-town voters who were more culturally conservative than urban dwellers.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    How did Joe Manchin in 2018 perform in his senate reelection compare to Hillary Clinton's\n",
    "    presidential comapaign in 2016? Can you provide specific information on how they both performed?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0b940a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 48 tokens\n",
      "> [retrieve] Total embedding token usage: 48 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 924 tokens\n",
      "> [get_response] Total LLM token usage: 924 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Joe Manchin's net rating fell by roughly 18 percentage points by the end of 2018, while Hillary Clinton lost the 2016 presidential election to Donald Trump. Specifically, Joe Manchin won his reelection in 2018, while Hillary Clinton lost the popular vote to Donald Trump by 2.1%.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    How did Joe Manchin in 2018 perform in his senate reelection compare to Hillary Clinton's\n",
    "    presidential comapaign in 2016? Can you provide specific information on how they both performed?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "add78b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 33 tokens\n",
      "> [retrieve] Total embedding token usage: 33 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1700 tokens\n",
      "> [get_response] Total LLM token usage: 1700 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The major campaign issues in the West Virginia Senate Race were Joe Manchin's defense of the coal industry, Sherrod Brown's opposition to much of U.S. trade policy, and Jon Tester's emphasis on his rancher credentials.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    What were major campaign issues in the West Virginia Senate Race.\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b1d87d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 21 tokens\n",
      "> [retrieve] Total embedding token usage: 21 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1662 tokens\n",
      "> [get_response] Total LLM token usage: 1662 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The major campaign issues in the West Virginia Senate Race were likely coal industry, U.S. trade policy, and gun measures. Senator Joe Manchin defended the coal industry, opposed much of U.S. trade policy, and was criticized by Hillary Clinton for some Senate votes against gun measures.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    What were major campaign issues in the West Virginia Senate Race.\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6067654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 31 tokens\n",
      "> [retrieve] Total embedding token usage: 31 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1677 tokens\n",
      "> [get_response] Total LLM token usage: 1677 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Joe Manchin, the Senator from West Virginia, defended the coal industry, which likely resonated with rural voters. The AP VoteCast survey found that 56 percent of rural and small-town residents voted for Republican House candidates, compared to 41 percent for Democrats. This suggests that Manchin likely performed well among rural voters.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    How did Joe Manchin perform among rural voters?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "78d34623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 19 tokens\n",
      "> [retrieve] Total embedding token usage: 19 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1660 tokens\n",
      "> [get_response] Total LLM token usage: 1660 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Joe Manchin, the Senator from West Virginia, likely performed well among rural voters. He is known for defending the coal industry, which is an important industry in rural areas. Additionally, he is known for opposing much of U.S. trade policy, which is also popular among rural voters.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# West Virginia\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    How did Joe Manchin perform among rural voters?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b3c062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 36 tokens\n",
      "> [retrieve] Total embedding token usage: 36 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 581 tokens\n",
      "> [get_response] Total LLM token usage: 581 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The major party nominees in the Montana Senate Race in 2018 are Jon Tester (Democrat) and Matt Rosendale (Republican).</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    Who are the major party nominess in the Montana Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "641300b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 24 tokens\n",
      "> [retrieve] Total embedding token usage: 24 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 855 tokens\n",
      "> [get_response] Total LLM token usage: 855 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The major party nominees in the Montana Senate Race in 2018 are Jon Tester (Democrat) and Matt Rosendale (Republican).</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Who are the major party nominess in the Montana Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa7195bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 33 tokens\n",
      "> [retrieve] Total embedding token usage: 33 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 868 tokens\n",
      "> [get_response] Total LLM token usage: 868 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Sen. Jon Tester of Montana won the Montana Senate Race in 2018.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    Who is the winner of the Montana Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52971f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 21 tokens\n",
      "> [retrieve] Total embedding token usage: 21 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 844 tokens\n",
      "> [get_response] Total LLM token usage: 844 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The winner of the Montana Senate Race in 2018 is Jon Tester, the Democratic incumbent.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Who is the winner of the Montana Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "111a0f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 39 tokens\n",
      "> [retrieve] Total embedding token usage: 39 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 622 tokens\n",
      "> [get_response] Total LLM token usage: 622 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Based on the information provided, it is not possible to answer this question. The documents provide information about Jon Tester's performance in the 2016 senate race, as well as his performance in the 2018 race so far. However, there is no information provided about how Jon Tester's performance compared to other 2018 senate races.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    How did Jon Tester perform in his 2018 senate reelection compared to other 2018 senate races?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b5a068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 27 tokens\n",
      "> [retrieve] Total embedding token usage: 27 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 634 tokens\n",
      "> [get_response] Total LLM token usage: 634 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Jon Tester's 2018 senate reelection was one of the most competitive of the 26 Democratic incumbents up for reelection in 2018. His net rating fell by roughly 18 percentage points by the end of the year, the most of any of the Democratic incumbents. He received an unexpected assist from an old ally, Chuck Hagel, and his independent streak could help him with independent voters, strong Democratic turnout, and some Republican defections in November.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    How did Jon Tester perform in his 2018 senate reelection compared to other 2018 senate races?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2a0c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 32 tokens\n",
      "> [retrieve] Total embedding token usage: 32 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1226 tokens\n",
      "> [get_response] Total LLM token usage: 1226 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Major campaign issues in the Montana Senate Race included veterans' matters, Jon Tester's independent streak, and Chuck Hagel's support for Tester. Additionally, Republican candidates Matt Rosendale and Troy Downing criticized Tester for his role in releasing what they called unsubstantiated claims against Jackson.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    What were major campaign issues in the Montana Senate Race.\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb5a6e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 20 tokens\n",
      "> [retrieve] Total embedding token usage: 20 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1190 tokens\n",
      "> [get_response] Total LLM token usage: 1190 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Major campaign issues in the Montana Senate Race included veterans' issues, Jon Tester's independent streak, and the Republican Party's response to President Trump's outbursts.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    What were major campaign issues in the Montana Senate Race.\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d6d92294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 36 tokens\n",
      "> [retrieve] Total embedding token usage: 36 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1652 tokens\n",
      "> [get_response] Total LLM token usage: 1652 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Jon Tester won his 2018 reelection race, suggesting that he performed well among rural voters. He played up his rancher credentials, which likely resonated with rural voters.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    How did Jon Tester perform among rural voters in his 2018 reelection race?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c7e2b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 24 tokens\n",
      "> [retrieve] Total embedding token usage: 24 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 868 tokens\n",
      "> [get_response] Total LLM token usage: 868 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Jon Tester's net rating fell by roughly 18 percentage points among rural voters by the end of the 2018 reelection race.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Montana\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    How did Jon Tester perform among rural voters in his 2018 reelection race?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93594488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 36 tokens\n",
      "> [retrieve] Total embedding token usage: 36 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 861 tokens\n",
      "> [get_response] Total LLM token usage: 861 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The major party nominees in the Utah Senate Race in 2018 are Republican Mitt Romney and Democrat Jenny Wilson.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utah\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    Who are the major party nominess in the Utah Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eb988d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 24 tokens\n",
      "> [retrieve] Total embedding token usage: 24 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 849 tokens\n",
      "> [get_response] Total LLM token usage: 849 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The major party nominees in the Utah Senate Race in 2018 are Republican Mitt Romney and Democrat Jenny Wilson.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utah\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Who are the major party nominess in the Utah Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f2d66a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 33 tokens\n",
      "> [retrieve] Total embedding token usage: 33 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1469 tokens\n",
      "> [get_response] Total LLM token usage: 1469 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The winner of the Utah Senate Race in 2018 is Republican Mitt Romney.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utah\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    Who is the winner of the Utah Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f9f5d713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 21 tokens\n",
      "> [retrieve] Total embedding token usage: 21 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 840 tokens\n",
      "> [get_response] Total LLM token usage: 840 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The winner of the Utah Senate Race in 2018 is Republican Mitt Romney.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utah\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Who is the winner of the Utah Senate Race in 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ad3e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 39 tokens\n",
      "> [retrieve] Total embedding token usage: 39 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1473 tokens\n",
      "> [get_response] Total LLM token usage: 1473 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The documents do not provide enough information to answer this question.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utah\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Using the documents, answer this question:\n",
    "    Why was there a swing from democrats to republicans in Utah from 2016 to 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "02913b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 27 tokens\n",
      "> [retrieve] Total embedding token usage: 27 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1538 tokens\n",
      "> [get_response] Total LLM token usage: 1538 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>In Utah, the Republican advantage was driven by a surge in turnout among rural and small-town whites. In 2016, they made up 28 percent of the electorate and voted for Republican House candidates by a margin of 57-41. In 2018, that share rose to 30 percent and they voted 63-35 for Republicans. This suggests that the enthusiasm among rural and small-town whites for Republican candidates was higher in 2018 than it was in 2016.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utah\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    Why was there a swing from democrats to republicans in Utah from 2016 to 2018?\n",
    "    \"\"\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
