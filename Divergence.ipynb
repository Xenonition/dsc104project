{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc55ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\William\n",
      "[nltk_data]     Nathan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\William\n",
      "[nltk_data]     Nathan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957b7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text(url):\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    article_divs = soup.find(\"div\", class_=\"page-content\")\n",
    "    article_ps = article_divs.find_all(\"p\")\n",
    "    article_text = \"\"\n",
    "    for p in article_ps:\n",
    "        article_text += p.get_text()\n",
    "        \n",
    "    return article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b031c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keywords(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords (common words that may not carry much meaning)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    \n",
    "    total = len(tokens)\n",
    "    \n",
    "    # Perform frequency analysis\n",
    "    freq_dist = FreqDist(tokens)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9502affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkwords = ['Republican', 'candidate', 'race']\n",
    "\n",
    "input_text = get_article_text(\"https://www.politico.com/news/2023/05/27/california-republicans-race-feinstein-senate-seat-00099053\")\n",
    "keywords = find_keywords(input_text)\n",
    "first_article = [keywords.count(word) / len(keywords) for word in checkwords]\n",
    "\n",
    "input_text = get_article_text(\"https://www.politico.com/news/2023/05/26/desantis-campaign-5-takeaways-00099070\")\n",
    "keywords = find_keywords(input_text)\n",
    "second_article = [keywords.count(word) / len(keywords) for word in checkwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf9231c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010602026390997967"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence = entropy(first_article, second_article)\n",
    "kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dc766c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0038854280869009264"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 0.5 * (np.array(first_article) + np.array(second_article))\n",
    "\n",
    "kl_pm = entropy(first_article, m)\n",
    "\n",
    "kl_qm = entropy(second_article, m)\n",
    "\n",
    "jsd = 0.5 * (kl_pm + kl_qm)\n",
    "jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cbf540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
